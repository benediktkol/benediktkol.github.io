<!-- Copyright (C) 2026 Benedikt Kolbeinsson -->
<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Primary Meta Tags -->
  <meta name="description" content="MEng thesis by Benedikt Kolbeinsson, Imperial College London, 2019">
  <meta name="keywords" content="MEng thesis, GANs, generative adversarial networks, domain adaptation, computer vision, machine learning, Imperial College London">
  <meta name="author" content="Benedikt Kolbeinsson">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">

  <link rel="canonical" href="https://benedikt.phd/meng/">

  <!-- Google Scholar Meta Tags -->
  <meta name="citation_title" content="Domain Transfer Between Images with GANs">
  <meta name="citation_author" content="Benedikt Kolbeinsson">
  <meta name="citation_publication_date" content="2019/6/1">
  <meta name="citation_dissertation_institution" content="Imperial College London">
  <meta name="citation_pdf_url" content="https://benedikt.phd/meng/Benedikt-Kolbeinsson-MEng-Thesis.pdf">
  <meta name="citation_keywords" content="machine learning; GANs; domain adaptation; computer vision; generative adversarial networks">

  <!-- Open Graph Meta Tags -->
  <meta property="og:title" content="Domain Transfer Between Images with GANs">
  <meta property="og:site_name" content="Benedikt Kolbeinsson">
  <meta property="og:type" content="article">
  <meta property="og:url" content="https://benedikt.phd/meng/">
  <meta property="og:description" content="MEng thesis by Benedikt Kolbeinsson, Imperial College London, 2019">
  <meta property="og:image" content="https://benedikt.phd/assets/images/banner.jpg">
  <meta property="og:image:alt" content="MEng thesis banner">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">

  <!-- Favicon -->
  <link rel="icon" type="image/svg+xml" href="../assets/favicon/favicon.svg">
  <link rel="icon" type="image/png" href="../assets/favicon/favicon.png">

  <!-- Fonts -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&family=JetBrains+Mono:wght@400;500&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Material+Symbols+Outlined:opsz,wght,FILL,GRAD@20..48,100..700,0..1,-50..200" rel="stylesheet">

  <!-- Stylesheets -->
  <link rel="stylesheet" href="../assets/css/style.css">
  <link rel="stylesheet" href="../assets/css/thesis.css">

  <title>Domain Transfer Between Images with GANs - MEng Thesis | Benedikt Kolbeinsson</title>

  <!-- Schema.org Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Thesis",
    "@id": "https://benedikt.phd/meng/#thesis",
    "name": "Domain Transfer Between Images with GANs",
    "author": { "@id": "https://benedikt.phd/#person" },
    "publisher": {
      "@type": "CollegeOrUniversity",
      "name": "Imperial College London",
      "url": "https://www.imperial.ac.uk/"
    },
    "datePublished": "2019-06-01",
    "educationalLevel": "Master's",
    "inSupportOf": "Master of Engineering (MEng)",
    "abstract": "Person re-identification (re-ID) is the problem of identifying the same person in multiple cameras. This is a non-trivial problem, that is confounded by non-overlapping field of view, lighting differences, occlusion, variation in poses and different camera viewpoints. Current person re-ID systems perform well on specific datasets but experience large performance drops when trained and tested on a different dataset. This report describes a new method to improve the robustness of person re-ID models. The proposed method generates new backgrounds using a generative adversarial network which allows person re-ID models to be trained on larger and more varied datasets, therefore improving robustness. Individual identities from the original dataset are recreated in new scenarios with corresponding labels, this allows person re-ID networks to utilise supervised learning on the generated data. Variations of the proposed method provide significant control over the generated images, from maintaining high similarity between the generated identities and their respective original (same pose) to generating the identity in any new pose while still maintaining significant similarities.",
    "keywords": ["machine learning","GANs","domain adaptation","computer vision"],
    "inLanguage": "en-GB",
    "url": "https://benedikt.phd/meng/",
    "mainEntityOfPage": {
      "@type": "WebPage",
      "@id": "https://benedikt.phd/meng/"
    },
    "encoding": {
      "@type": "MediaObject",
      "contentUrl": "https://benedikt.phd/meng/Benedikt-Kolbeinsson-MEng-Thesis.pdf",
      "encodingFormat": "application/pdf"
    }
  }
  </script>
</head>

<body>
  <main class="thesis-page">
    <div class="container">
      <a href="/" class="back-link">Back to homepage</a>

      <div class="thesis-header">
        <h1 class="heading-text">Domain Transfer Between Images with GANs</h1>
        <p class="thesis-subtitle">MEng Thesis</p>

        <div class="thesis-meta">
          <div class="thesis-meta-item">
            <span class="mono-text">Author:</span>
            <span>Benedikt Kolbeinsson</span>
          </div>
          <div class="thesis-meta-item">
            <span class="mono-text">Institution:</span>
            <span>Imperial College London</span>
          </div>
          <div class="thesis-meta-item">
            <span class="mono-text">Programme:</span>
            <span>Electrical and Electronic Engineering with Management</span>
          </div>
          <div class="thesis-meta-item">
            <span class="mono-text">Degree:</span>
            <span>Master of Engineering (MEng)</span>
          </div>
        </div>
      </div>

      <div class="thesis-content">
        <div class="thesis-access-card">
          <h3 class="thesis-access-title">Full Thesis</h3>
          <p class="thesis-access-meta">PDF Document â€¢ 19.6 MB</p>
          <div class="thesis-actions">
            <a href="/meng/Benedikt-Kolbeinsson-MEng-Thesis.pdf" class="thesis-action-btn primary" target="_blank" rel="noopener">
              <span class="material-symbols-outlined">open_in_new</span>
              Open
            </a>
            <a href="/meng/Benedikt-Kolbeinsson-MEng-Thesis.pdf" class="thesis-action-btn secondary" download="Benedikt-Kolbeinsson-MEng-Thesis.pdf">
              <span class="material-symbols-outlined">download</span>
              Download
            </a>
          </div>
        </div>

        <div class="thesis-section">
          <h2>Abstract</h2>
          <p>
            Person re-identification (re-ID) is the problem of identifying the same person in multiple cameras. This is a non-trivial problem, that is confounded by non-overlapping field of view, lighting differences, occlusion, variation in poses and different camera viewpoints. Current person re-ID systems perform well on specific datasets but experience large performance drops when trained and tested on a different dataset.
          </p>
          <p>
            This report describes a new method to improve the robustness of person re-ID models. The proposed method generates new backgrounds using a generative adversarial network which allows person re-ID models to be trained on larger and more varied datasets, therefore improving robustness. Individual identities from the original dataset are recreated in new scenarios with corresponding labels, this allows person re-ID networks to utilise supervised learning on the generated data.
          </p>
          <p>
            Variations of the proposed method provide significant control over the generated images, from maintaining high similarity between the generated identities and their respective original (same pose) to generating the identity in any new pose while still maintaining significant similarities.
          </p>
        </div>

        <div class="thesis-section">
          <h2>Keywords</h2>
          <div class="keywords">
            <span class="keyword-tag">Machine Learning</span>
            <span class="keyword-tag">Generative Adversarial Networks</span>
            <span class="keyword-tag">Domain Adaptation</span>
            <span class="keyword-tag">Computer Vision</span>
            <span class="keyword-tag">Image Translation</span>
            <span class="keyword-tag">Deep Learning</span>
            <span class="keyword-tag">Neural Networks</span>
          </div>
        </div>

        <div class="thesis-section">
          <h2>Citation</h2>
          <div class="citation-box">
            Kolbeinsson, B. (2019). <i>Domain Transfer Between Images with GANs</i>. Master's thesis, Imperial College London.
          </div>

          <div class="bibtex-section">
            <h3>BibTeX</h3>
            <div class="bibtex-container">
              <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy to clipboard">
                <span class="material-symbols-outlined">content_copy</span>
              </button>
              <pre class="bibtex-code" id="bibtex-content">@mastersthesis{kolbeinsson2019gans,
  author = {Benedikt Kolbeinsson},
  title  = {Domain Transfer Between Images with GANs},
  school = {Imperial College London},
  year   = {2019},
  type   = {MEng Thesis}
}</pre>
            </div>
          </div>
        </div>
      </div>
    </div>
  </main>

  <script>
    function copyBibTeX() {
      const bibtexContent = document.getElementById('bibtex-content').textContent;
      navigator.clipboard.writeText(bibtexContent).then(() => {
        const btn = document.querySelector('.copy-bibtex-btn');
        const icon = btn.querySelector('.material-symbols-outlined');
        btn.classList.add('copied');
        icon.textContent = 'done';
        setTimeout(() => {
          btn.classList.remove('copied');
          icon.textContent = 'content_copy';
        }, 2000);
      });
    }
  </script>
</body>
</html>